{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import input_data\n",
    "import model\n",
    "\n",
    "\n",
    "N_CLASSES = 2  # 2 types of pics\n",
    "IMG_W = 64  # pics resizing, original sizes were too big to train in a short time, took more than 1 day\n",
    "IMG_H = 64\n",
    "BATCH_SIZE = 20\n",
    "CAPACITY = 2000\n",
    "MAX_STEP = 10000  # should be >10K\n",
    "learning_rate = 0.0001  # should be <0.0001\n",
    "\n",
    "# gaining batch\n",
    "train_dir = 'L:/ICL/Vase_project/pics'  # file dir\n",
    "logs_train_dir = 'L:/ICL/Vase_project/pics_input_data/logs'  # logs saving dir\n",
    "\n",
    "# train, train_label = input_data.get_files(train_dir)\n",
    "train, train_label, val, val_label = input_data.get_files(train_dir, 0.3)\n",
    "# training data & tags\n",
    "train_batch, train_label_batch = input_data.get_batch(train, train_label, IMG_W, IMG_H, BATCH_SIZE, CAPACITY)\n",
    "# testing data & tags\n",
    "val_batch, val_label_batch = input_data.get_batch(val, val_label, IMG_W, IMG_H, BATCH_SIZE, CAPACITY)\n",
    "\n",
    "# def training move\n",
    "train_logits = model.inference(train_batch, BATCH_SIZE, N_CLASSES)\n",
    "train_loss = model.losses(train_logits, train_label_batch)\n",
    "train_op = model.trainning(train_loss, learning_rate)\n",
    "train_acc = model.evaluation(train_logits, train_label_batch)\n",
    "\n",
    "# def testing move\n",
    "test_logits = model.inference(val_batch, BATCH_SIZE, N_CLASSES)\n",
    "test_loss = model.losses(test_logits, val_label_batch)\n",
    "test_acc = model.evaluation(test_logits, val_label_batch)\n",
    "\n",
    "# log summary\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "sess = tf.Session()\n",
    "train_writer = tf.summary.FileWriter(logs_train_dir, sess.graph)\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "# batch training\n",
    "try:\n",
    "    # MAX_STEP training, 1 batch 1 step\n",
    "    for step in np.arange(MAX_STEP):\n",
    "        if coord.should_stop():\n",
    "            break\n",
    "        _, tra_loss, tra_acc = sess.run([train_op, train_loss, train_acc])\n",
    "\n",
    "        # 50 steps to print loss & acc，take down log，write in writer\n",
    "        if step % 10 == 0:\n",
    "            print('Step %d, train loss = %.2f, train accuracy = %.2f%%' % (step, tra_loss, tra_acc * 100.0))\n",
    "            summary_str = sess.run(summary_op)\n",
    "            train_writer.add_summary(summary_str, step)\n",
    "        # every 100 steps to save model once\n",
    "        if (step + 1) == MAX_STEP:\n",
    "            checkpoint_path = os.path.join(logs_train_dir, 'model.ckpt')\n",
    "            saver.save(sess, checkpoint_path, global_step=step)\n",
    "\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print('Done training -- epoch limit reached')\n",
    "\n",
    "finally:\n",
    "    coord.request_stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
